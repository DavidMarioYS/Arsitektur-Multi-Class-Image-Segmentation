{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee91d3-ca78-4247-84ab-31e9f7cb2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272b78a-f954-44ac-b1dc-67f45ae7f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "# Define the folder paths\n",
    "path = 'C:\\\\Users\\\\Admin\\\\Documents\\\\SKRIPSI\\\\DATASET\\\\PREPROCESSING\\\\256'\n",
    "source_ori = 'C:\\\\Users\\\\Admin\\\\Documents\\\\SKRIPSI\\\\DATASET\\\\PREPROCESSING\\\\256\\\\augmentation\\\\original'\n",
    "source_gt = 'C:\\\\Users\\\\Admin\\\\Documents\\\\SKRIPSI\\\\DATASET\\\\PREPROCESSING\\\\256\\\\augmentation\\\\ground_truth'\n",
    "\n",
    "def analyze_images(folder_path):\n",
    "    total_images = 0\n",
    "    total_size = [0, 0]  # Width, Height\n",
    "    total_pixels = 0\n",
    "    color_modes = []\n",
    "    file_formats = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            total_images += 1\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            with Image.open(img_path) as img:\n",
    "                width, height = img.size\n",
    "                total_size[0] += width\n",
    "                total_size[1] += height\n",
    "                total_pixels += width * height\n",
    "                color_modes.append(img.mode)\n",
    "                file_formats.append(img.format)\n",
    "\n",
    "    # Calculate average size\n",
    "    if total_images > 0:\n",
    "        avg_size = (total_size[0] // total_images, total_size[1] // total_images)\n",
    "        avg_total_pixels = total_pixels / total_images\n",
    "        most_common_color_mode = Counter(color_modes).most_common(1)[0][0]\n",
    "        most_common_format = Counter(file_formats).most_common(1)[0][0]\n",
    "    else:\n",
    "        avg_size = (0, 0)\n",
    "        avg_total_pixels = 0\n",
    "        most_common_color_mode = None\n",
    "        most_common_format = None\n",
    "\n",
    "    return {\n",
    "        \"Total Gambar\": total_images,\n",
    "        \"Rata-rata Ukuran Gambar\": avg_size,\n",
    "        \"Rata-rata Total Piksel\": avg_total_pixels,\n",
    "        \"Mode Warna Paling Sering\": most_common_color_mode,\n",
    "        \"Format File\": most_common_format\n",
    "    }\n",
    "\n",
    "# Analyze both folders\n",
    "results = {\n",
    "    \"Original\": analyze_images(source_ori),\n",
    "    \"Ground Truth\": analyze_images(source_gt)\n",
    "}\n",
    "\n",
    "# Display results\n",
    "for folder_name, info in results.items():\n",
    "    print(f\"Hasil Analisis untuk Folder {folder_name}:\")\n",
    "    print(f\"Total Gambar: {info['Total Gambar']}\")\n",
    "    print(f\"Rata-rata Ukuran Gambar: ({info['Rata-rata Ukuran Gambar'][0]:.2f} x {info['Rata-rata Ukuran Gambar'][1]:.2f})\")\n",
    "    print(f\"Rata-rata Total Piksel: {info['Rata-rata Total Piksel']:.2f}\")\n",
    "    print(f\"Mode Warna Paling Sering: {info['Mode Warna Paling Sering']}\")\n",
    "    print(f\"Format File: {info['Format File']}\\n\")\n",
    "\n",
    "# Ensure that the number of images in the Original and Ground Truth folders is the same\n",
    "assert results[\"Original\"][\"Total Gambar\"] == results[\"Ground Truth\"][\"Total Gambar\"], \"Jumlah gambar di folder ORI dan GT tidak sama\"\n",
    "\n",
    "# Ensure that the average image size in both folders is the same\n",
    "assert results[\"Original\"][\"Rata-rata Ukuran Gambar\"] == results[\"Ground Truth\"][\"Rata-rata Ukuran Gambar\"], \"Rata-rata ukuran gambar di folder ORI dan GT tidak sama\"\n",
    "\n",
    "# Ensure that the average total pixels in both folders are the same\n",
    "assert results[\"Original\"][\"Rata-rata Total Piksel\"] == results[\"Ground Truth\"][\"Rata-rata Total Piksel\"], \"Rata-rata total piksel di folder ORI dan GT tidak sama\"\n",
    "\n",
    "# Ensure that the most common color mode in both folders is the same\n",
    "assert results[\"Original\"][\"Mode Warna Paling Sering\"] == results[\"Ground Truth\"][\"Mode Warna Paling Sering\"], \"Mode warna paling sering di folder ORI dan GT tidak sama\"\n",
    "\n",
    "# Ensure that the file formats in both folders are the same\n",
    "assert results[\"Original\"][\"Format File\"] == results[\"Ground Truth\"][\"Format File\"], \"Format file di folder ORI dan GT tidak sama\"\n",
    "\n",
    "print(\"\\nSemua pengujian berhasil! Folder original dan ground_truth memiliki data gambar yang sama.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f8d23b-7271-4ed2-8c5c-c3db3e91f99b",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8a560-481c-4964-b00e-2779c96023fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "# Folder tujuan untuk train, validation, dan test di bawah base\n",
    "train_dir = path + '\\\\split\\\\augmentasi\\\\train'\n",
    "val_dir = path + '\\\\split\\\\augmentasi\\\\val'\n",
    "test_dir = path + '\\\\split\\\\augmentasi\\\\test'\n",
    "\n",
    "# Membuat folder untuk train, validation, dan test\n",
    "os.makedirs(os.path.join(train_dir, 'original'), exist_ok=True)\n",
    "os.makedirs(os.path.join(train_dir, 'ground_truth'), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, 'original'), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, 'ground_truth'), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, 'original'), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, 'ground_truth'), exist_ok=True)\n",
    "\n",
    "\n",
    "# Mendapatkan semua file gambar dan mask\n",
    "original_files = sorted(os.listdir(source_ori))\n",
    "ground_truth_files = sorted(os.listdir(source_gt))\n",
    "\n",
    "# Pengecekan apakah jumlah file gambar dan mask sama\n",
    "if len(original_files) != len(ground_truth_files):\n",
    "    print(f\"WARNING: Jumlah gambar asli ({len(original_files)}) tidak sama dengan jumlah mask ({len(ground_truth_files)})\")\n",
    "else:\n",
    "    print(f\"Jumlah gambar dan mask sesuai: {len(original_files)} file\")\n",
    "\n",
    "# Rasio pembagian dataset\n",
    "train_ratio = 0.8  # 80% untuk train\n",
    "val_ratio = 0.1    # 10% untuk validation\n",
    "test_ratio = 0.1   # 10% untuk test\n",
    "\n",
    "# Pastikan rasio totalnya 1.0\n",
    "if (train_ratio + val_ratio + test_ratio) != 1.0:\n",
    "    raise ValueError(\"Rasio train, validation, dan test harus berjumlah 1.0\")\n",
    "\n",
    "# Membagi dataset menjadi train, val, test\n",
    "train_original, temp_original, train_ground_truth, temp_ground_truth = train_test_split(\n",
    "    original_files, ground_truth_files, test_size=(1.0 - train_ratio), random_state=42)\n",
    "\n",
    "val_size = val_ratio / (val_ratio + test_ratio)  # Menghitung rasio validasi terhadap (validasi + test)\n",
    "\n",
    "val_original, test_original, val_ground_truth, test_ground_truth = train_test_split(\n",
    "    temp_original, temp_ground_truth, test_size=(1.0 - val_size), random_state=42)\n",
    "\n",
    "# Fungsi untuk menyalin file ke direktori yang tepat\n",
    "def copy_files(original_list, ground_truth_list, folder):\n",
    "    if not original_list or not ground_truth_list:\n",
    "        print(f\"ERROR: Tidak ada file untuk diproses di {folder}\")\n",
    "        return\n",
    "\n",
    "    for orig, gt in zip(original_list, ground_truth_list):\n",
    "        shutil.copy(os.path.join(source_ori, orig), os.path.join(folder, 'original', orig))\n",
    "        shutil.copy(os.path.join(source_gt, gt), os.path.join(folder, 'ground_truth', gt))\n",
    "\n",
    "    print(f\"{len(original_list)} file berhasil disalin ke {folder}\")\n",
    "\n",
    "# Menyalin file ke folder masing-masing\n",
    "copy_files(train_original, train_ground_truth, train_dir)\n",
    "copy_files(val_original, val_ground_truth, val_dir)\n",
    "copy_files(test_original, test_ground_truth, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ddd858-3c1d-472a-9450-d4b94ce12e64",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e1731-e09f-4b64-b311-4604f69453b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert RGB to HEX color codes\n",
    "def rgb_to_hex(rgb):\n",
    "    \"\"\"Convert RGB to HEX color code.\"\"\"\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(rgb[0], rgb[1], rgb[2])\n",
    "\n",
    "# Encode the mask image into class indices\n",
    "def encode_mask(mask_image, tolerance=3):\n",
    "    \"\"\"Encode the mask based on RGB values into class labels.\"\"\"\n",
    "    # Replace black background with green (assuming black is not a valid class)\n",
    "    mask_image[np.all(mask_image == [0, 0, 0], axis=-1)] = [0, 255, 0]\n",
    "\n",
    "    # Initialize encoded mask\n",
    "    encoded_mask = np.zeros((mask_image.shape[0], mask_image.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    # Define class masks based on RGB color values with tolerance\n",
    "    red_mask = np.all(np.abs(mask_image - [255, 0, 0]) <= tolerance, axis=-1)\n",
    "    encoded_mask[red_mask] = 0\n",
    "\n",
    "    green_mask = np.all(np.abs(mask_image - [0, 255, 0]) <= tolerance, axis=-1)\n",
    "    encoded_mask[green_mask] = 2\n",
    "\n",
    "    blue_mask = np.all(np.abs(mask_image - [0, 0, 255]) <= tolerance, axis=-1)\n",
    "    encoded_mask[blue_mask] = 1\n",
    "\n",
    "    return encoded_mask\n",
    "\n",
    "# One-hot encode the encoded mask\n",
    "def one_hot_encode(encoded_mask, num_classes=3):\n",
    "    \"\"\"Convert the encoded mask into a one-hot encoded mask.\"\"\"\n",
    "    one_hot_mask = np.eye(num_classes)[encoded_mask]\n",
    "    return one_hot_mask\n",
    "\n",
    "# Load images and masks, then apply encoding and resizing\n",
    "def load_and_one_hot_encode(original_dir, mask_dir, target_size=None):\n",
    "    \"\"\"Load images and masks, resize them, and apply one-hot encoding.\"\"\"\n",
    "    images = []\n",
    "    masks = []\n",
    "    one_hot_masks = []\n",
    "\n",
    "    image_files = sorted(os.listdir(original_dir))\n",
    "    mask_files = sorted(os.listdir(mask_dir))\n",
    "\n",
    "    for img_file, mask_file in zip(image_files, mask_files):\n",
    "        # Read images and convert to RGB\n",
    "        img = cv2.cvtColor(cv2.imread(os.path.join(original_dir, img_file)), cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(cv2.imread(os.path.join(mask_dir, mask_file)), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize if target_size is specified\n",
    "        if target_size is not None:\n",
    "            img = cv2.resize(img, target_size)\n",
    "            mask = cv2.resize(mask, target_size)\n",
    "\n",
    "        # Ensure the image and mask have the same dimensions\n",
    "        if img.shape[:2] == mask.shape[:2]:\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "\n",
    "            # Encode the mask and apply one-hot encoding\n",
    "            encoded_mask = encode_mask(mask)\n",
    "            one_hot_mask = one_hot_encode(encoded_mask)\n",
    "            one_hot_masks.append(one_hot_mask)\n",
    "        else:\n",
    "            print(f\"Size mismatch for {img_file} ({img.shape}) and {mask_file} ({mask.shape}). Skipping...\")\n",
    "\n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "    one_hot_masks = np.array(one_hot_masks)\n",
    "\n",
    "    return images, masks, one_hot_masks\n",
    "\n",
    "# Convert one-hot encoded mask to an RGB image for visualization\n",
    "def convert_to_rgb(one_hot_visual, colormap):\n",
    "    \"\"\"Convert one-hot encoded mask to an RGB image for visualization.\"\"\"\n",
    "    shape = one_hot_visual.shape\n",
    "    rgb_image = np.zeros((shape[0], shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Map each class index to its corresponding color\n",
    "    for class_index, color in colormap.items():\n",
    "        rgb_image[one_hot_visual == class_index] = color\n",
    "\n",
    "    return rgb_image\n",
    "\n",
    "# Visualize original image, ground truth mask, one-hot mask, and the RGB-encoded mask\n",
    "def visualize_sample(image, mask, one_hot_mask, colormap):\n",
    "    \"\"\"Visualize the original image, mask, one-hot encoded mask, and RGB encoded mask.\"\"\"\n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    one_hot_visual = np.argmax(one_hot_mask, axis=-1)\n",
    "\n",
    "    # Debugging output to check the unique classes\n",
    "    print(\"Unique classes in one_hot_visual:\", np.unique(one_hot_visual))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Original Image (RGB)')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask)\n",
    "    plt.title('Ground Truth Mask')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    rgb_encoded_mask = convert_to_rgb(one_hot_visual, colormap)\n",
    "    plt.imshow(rgb_encoded_mask)\n",
    "    plt.title('One-Hot Encoded Mask (RGB)')\n",
    "    plt.show()\n",
    "\n",
    "# Define directories for training, validation, and test data\n",
    "base_split = 'C:\\\\Users\\\\Admin\\\\Documents\\\\SKRIPSI\\\\DATASET\\\\PREPROCESSING\\\\256\\\\split\\\\augmentasi'\n",
    "train_original_dir = os.path.join(base_split, \"train\", \"original\")\n",
    "train_mask_dir = os.path.join(base_split, \"train\", \"ground_truth\")\n",
    "val_original_dir = os.path.join(base_split, \"val\", \"original\")\n",
    "val_mask_dir = os.path.join(base_split, \"val\", \"ground_truth\")\n",
    "test_original_dir = os.path.join(base_split, \"test\", \"original\")\n",
    "test_mask_dir = os.path.join(base_split, \"test\", \"ground_truth\")\n",
    "\n",
    "target_size = (256, 256)\n",
    "\n",
    "# Load and one-hot encode training and validation sets\n",
    "train_images, train_masks, train_one_hot_masks = load_and_one_hot_encode(train_original_dir, train_mask_dir, target_size)\n",
    "val_images, val_masks, val_one_hot_masks = load_and_one_hot_encode(val_original_dir, val_mask_dir, target_size)\n",
    "\n",
    "# Assign data to training and validation sets\n",
    "X_train = train_images\n",
    "y_train = train_one_hot_masks\n",
    "\n",
    "X_val = val_images\n",
    "y_val = val_one_hot_masks\n",
    "\n",
    "# Test set (loading only the paths, loading the images should be done similarly as train/val if needed)\n",
    "X_test = test_original_dir\n",
    "y_test = test_mask_dir\n",
    "\n",
    "# Print shapes of the datasets for verification\n",
    "print(\"Train Shapes:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "\n",
    "print(\"\\nValidation Shapes:\")\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"y_val:\", y_val.shape)\n",
    "\n",
    "# Define colormap for each class index\n",
    "colormap = {\n",
    "    0: [255, 0, 0],    # Red\n",
    "    2: [0, 255, 0],    # Green\n",
    "    1: [0, 0, 255],    # Blue\n",
    "}\n",
    "# Print class information and hex color codes\n",
    "print(\"\\nClass Information and Hex Color Codes:\")\n",
    "for class_index, color in colormap.items():\n",
    "    hex_color = rgb_to_hex(color)\n",
    "    print(f'Class {class_index}: {hex_color}')\n",
    "\n",
    "# Visualize a sample from the training set\n",
    "index = 2  # Change this to visualize other samples\n",
    "visualize_sample(X_train[index], train_masks[index], y_train[index], colormap)\n",
    "\n",
    "# Visualize a sample from the validation set\n",
    "index_val = 10  # Change this to visualize other samples\n",
    "visualize_sample(X_val[index_val], val_masks[index_val], y_val[index_val], colormap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00b078-9c89-4da4-9048-ce09529a3974",
   "metadata": {},
   "source": [
    "# Model Arsitektur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2099da-0521-4370-9283-ed88c4241596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BiSeNetV3 + EfficientNetB1\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Conv2D, BatchNormalization, ReLU,\n",
    "                                     GlobalAveragePooling2D, Reshape, Multiply,\n",
    "                                     Add, Input, Concatenate, Conv2DTranspose)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB1\n",
    "\n",
    "# Squeeze-and-Excitation Block (tidak berubah)\n",
    "def se_block(x, reduction_ratio=16):\n",
    "    filters = x.shape[-1]\n",
    "    se = GlobalAveragePooling2D()(x)\n",
    "    se = Reshape((1, 1, filters))(se)\n",
    "    se = Conv2D(filters // reduction_ratio, 1, activation='relu')(se)\n",
    "    se = Conv2D(filters, 1, activation='sigmoid')(se)\n",
    "    return Multiply()([x, se])\n",
    "\n",
    "# Adaptive Receptive Field Block\n",
    "def adaptive_rf_block(x, filters):\n",
    "    # Dilated convolutions for adaptive receptive fields\n",
    "    dilate1 = Conv2D(filters, 3, padding='same', dilation_rate=1, activation='relu')(x)\n",
    "    dilate2 = Conv2D(filters, 3, padding='same', dilation_rate=2, activation='relu')(x)\n",
    "    dilate3 = Conv2D(filters, 3, padding='same', dilation_rate=4, activation='relu')(x)\n",
    "    return Add()([dilate1, dilate2, dilate3])\n",
    "\n",
    "# Detail Branch (sama seperti di BiSeNetV2)\n",
    "def detail_branch(input_tensor):\n",
    "    x = Conv2D(64, 3, 2, padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(64, 3, 1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Stage 2\n",
    "    x = Conv2D(128, 3, 2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    for _ in range(2):\n",
    "        x_res = Conv2D(128, 3, 1, padding='same')(x)\n",
    "        x_res = BatchNormalization()(x_res)\n",
    "        x_res = ReLU()(x_res)\n",
    "        x_res = Conv2D(128, 3, 1, padding='same')(x_res)\n",
    "        x_res = BatchNormalization()(x_res)\n",
    "        x = Add()([x, x_res])\n",
    "        x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "# Semantic Branch with Context Embedding\n",
    "def semantic_branch(input_tensor):\n",
    "    # Use EfficientNetB1 as the backbone\n",
    "    base_model = EfficientNetB1(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "    # Extract features from a specific layer\n",
    "    x = base_model.get_layer(\"block6a_expand_activation\").output  # Layer EfficientNetB1\n",
    "    x = Conv2D(128, 1, padding='same')(x)  # Channel reduction\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Context embedding\n",
    "    x = adaptive_rf_block(x, filters=128)\n",
    "    x = se_block(x)  # SE block for feature enhancement\n",
    "    return x\n",
    "\n",
    "# Feature Fusion Module (FFM)\n",
    "def feature_fusion(detail, semantic):\n",
    "    # Apply detail guidance\n",
    "    detail_guidance = Conv2D(128, 3, padding='same')(detail)\n",
    "    detail_guidance = BatchNormalization()(detail_guidance)\n",
    "    detail_guidance = ReLU()(detail_guidance)\n",
    "\n",
    "    # Upsample semantic branch output\n",
    "    semantic = Conv2DTranspose(128, (4, 4), strides=(4, 4), padding='same')(semantic)\n",
    "    semantic_guidance = Conv2D(128, 3, padding='same')(semantic)\n",
    "    semantic_guidance = BatchNormalization()(semantic_guidance)\n",
    "    semantic_guidance = ReLU()(semantic_guidance)\n",
    "\n",
    "    # Concatenate and apply attention mechanism\n",
    "    fusion = Concatenate()([detail_guidance, semantic_guidance])\n",
    "    fusion = Conv2D(128, 3, padding='same')(fusion)\n",
    "    fusion = BatchNormalization()(fusion)\n",
    "    fusion = ReLU()(fusion)\n",
    "\n",
    "    fusion = se_block(fusion)  # Adding SE block to refine features\n",
    "    return fusion\n",
    "\n",
    "# Create BiSeNetV3 Model with EfficientNetB1 backbone\n",
    "def create_bisenetv3(input_shape=(256, 256, 3), num_classes=3):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Detail Branch\n",
    "    detail = detail_branch(inputs)\n",
    "\n",
    "    # Semantic Branch\n",
    "    semantic = semantic_branch(inputs)\n",
    "\n",
    "    # Feature Fusion\n",
    "    x = feature_fusion(detail, semantic)\n",
    "\n",
    "    # Final layers with transpose convolution for upsampling\n",
    "    x = Conv2D(128, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Upsample output to match input size\n",
    "    x = Conv2DTranspose(num_classes, (4, 4), strides=(4, 4), padding='same', activation='softmax')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=x, name=\"BiSeNetV3_EfficientNetB1\")\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_bisenetv3(input_shape=(256, 256, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdad702-f11f-456f-8434-223b5803e6e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Menampilkan Visual Arsitektur Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Path ke folder output untuk hasil augmentasi images dan ground truth\n",
    "architecture = 'C:\\\\Users\\\\Admin\\\\Documents\\\\SKRIPSI\\\\Kode\\\\Model\\\\BiSeNetV3\\\\Architecture'\n",
    "os.makedirs(architecture, exist_ok=True)\n",
    "\n",
    "# Misalnya, model adalah nama variabel yang berisi arsitektur model Keras\n",
    "plot_model(model, to_file='C:\\\\Users\\\\Admin\\\\Documents\\\\SKRIPSI\\\\Kode\\\\Model\\\\BiSeNetV3\\\\Architecture\\\\BiSeNetV3_EfficientNetB1_256.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a480a83-b585-4567-9a40-cdb962ab6efb",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f7179-e59b-4928-b4a1-e5843f923214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=False, verbose=1)\n",
    "\n",
    "# Model Checkpoint\n",
    "model_checkpoint = ModelCheckpoint( filepath='.//model//256A_B8E100_BiSeNetV3-EfficientNetB1.keras', monitor='val_loss', mode='min', save_best_only=False, verbose=1)\n",
    "\n",
    "# Reduce Learning Rate\n",
    "reduce_lr = ReduceLROnPlateau( monitor='val_loss', factor=0.1, patience=5, mode='min', min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Buat direktori log untuk TensorBoard\n",
    "log_dir = \"logs/fit/A-B8E100\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True\n",
    ")\n",
    "\n",
    "# # Combine all callbacks\n",
    "callbacks = [early_stopping, model_checkpoint, reduce_lr, tensorboard]\n",
    "\n",
    "# Mengukur waktu komputasi saat pelatihan\n",
    "start_time = time.time()\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Latih model dan simpan riwayat pelatihan\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=8,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks = callbacks)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Ukuran model dalam byte\n",
    "model_size = model.count_params() * 4  # Menghitung ukuran model dalam byte (asumsi float32)\n",
    "\n",
    "print(f'Waktu Komputasi untuk Pelatihan: {training_time:.2f} detik')\n",
    "print(f'Ukur Model: {model_size / (1024 ** 2):.2f} MB')  # Mengonversi ke MB\n",
    "\n",
    "# Visualisasi loss\n",
    "# Menentukan epoch terbaik berdasarkan val_loss\n",
    "best_epoch = history.history['val_loss'].index(min(history.history['val_loss']))\n",
    "best_val_loss = history.history['val_loss'][best_epoch]\n",
    "\n",
    "# Menentukan val_accuracy terbaik pada epoch terbaik\n",
    "best_val_acc = history.history['val_accuracy'][best_epoch]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "# Menambahkan garis vertikal pada epoch terbaik\n",
    "plt.axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Epoch ({best_epoch+1})')\n",
    "\n",
    "# Menambahkan teks di atas garis vertikal\n",
    "plt.text(best_epoch, best_val_loss + 0.1,  # Posisi teks sedikit di atas titik\n",
    "         f'Epoch {best_epoch+1}\\nVal Loss: {best_val_loss:.4f}', \n",
    "         color='red', fontsize=10, ha='center')\n",
    "\n",
    "plt.title('Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot akurasi\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "\n",
    "# Menambahkan garis vertikal pada epoch terbaik\n",
    "plt.axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Epoch ({best_epoch+1})')\n",
    "\n",
    "# Menambahkan teks di atas garis vertikal\n",
    "best_val_acc = history.history['val_accuracy'][best_epoch]\n",
    "plt.text(best_epoch, best_val_acc + 0.02,  # Posisi teks sedikit di atas titik\n",
    "         f'Epoch {best_epoch+1}\\nVal Acc: {best_val_acc:.4f}', \n",
    "         color='red', fontsize=10, ha='center')\n",
    "\n",
    "plt.title('Accuracy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe93a9ba-558e-4f8a-ad3c-c12e7a174e6b",
   "metadata": {},
   "source": [
    "# Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccbe924-ca63-48eb-93e6-1fe437cc9d0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, jaccard_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualisasi dengan Metriks Evaluasi\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    \"\"\"Menghitung Dice Coefficient\"\"\"\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection + 1e-7) / (np.sum(y_true) + np.sum(y_pred) + 1e-7)\n",
    "\n",
    "def iou_score(y_true, y_pred):\n",
    "    \"\"\"Menghitung IoU Score\"\"\"\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return (intersection + 1e-7) / (union + 1e-7)\n",
    "\n",
    "def convert_to_rgb(mask, colormap):\n",
    "    \"\"\"Konversi mask kelas ke RGB menggunakan colormap\"\"\"\n",
    "    h, w = mask.shape\n",
    "    rgb_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for cls in range(len(colormap)):\n",
    "        rgb_mask[mask == cls] = colormap[cls]\n",
    "    return rgb_mask\n",
    "\n",
    "def overlay_images(original, mask, opacity=0.5):\n",
    "    \"\"\"Menggabungkan gambar asli dan mask dengan efek transparansi.\"\"\"\n",
    "    overlay = cv2.addWeighted(original, 1 - opacity, mask, opacity, 0)\n",
    "    return overlay\n",
    "\n",
    "def evaluate_model_on_val_data(model, X_val, y_val, colormap):\n",
    "    \"\"\"\n",
    "    Mengevaluasi model pada data val dan menampilkan hasil prediksi dengan metrik evaluasi, overlay, dan waktu komputasi.\n",
    "    \n",
    "    Args:\n",
    "        model: Model yang telah dilatih.\n",
    "        X_val: Gambar input val.\n",
    "        y_val: Ground truth mask val.\n",
    "        colormap: Dictionary yang berisi peta warna untuk setiap kelas.\n",
    "    \"\"\"\n",
    "    predictions = model.predict(X_val)\n",
    "    predictions_class_index = np.argmax(predictions, axis=-1)\n",
    "    y_val_class_index = np.argmax(y_val, axis=-1)\n",
    "\n",
    "    num_classes = y_val.shape[-1]\n",
    "    mean_dice = np.zeros(num_classes)\n",
    "    mean_iou = np.zeros(num_classes)\n",
    "    \n",
    "    num_samples = X_val.shape[0]  # Total sample in the val set\n",
    "    computation_times = []  # List to store computation times for each prediction\n",
    "    \n",
    "    # Tampilkan beberapa sampel hasil prediksi\n",
    "    for i in range(num_samples):\n",
    "        start_time = time.time()  # Start the timer for prediction\n",
    "        \n",
    "        plt.figure(figsize=(18, 6))\n",
    "        \n",
    "        # Gambar asli\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(X_val[i])\n",
    "        plt.title('Original Image')\n",
    "\n",
    "        # Ground truth mask\n",
    "        plt.subplot(1, 4, 2)\n",
    "        ground_truth_rgb = convert_to_rgb(y_val_class_index[i], colormap)\n",
    "        plt.imshow(ground_truth_rgb)\n",
    "        plt.title('Ground Truth Mask')\n",
    "\n",
    "        # Prediksi mask\n",
    "        plt.subplot(1, 4, 3)\n",
    "        predicted_rgb = convert_to_rgb(predictions_class_index[i], colormap)\n",
    "        plt.imshow(predicted_rgb)\n",
    "        plt.title('Predicted Mask')\n",
    "        \n",
    "        # Overlay gambar asli dengan prediksi\n",
    "        overlay = overlay_images(X_val[i], predicted_rgb, opacity=0.4)  # Ubah opacity sesuai keinginan\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(overlay)\n",
    "        plt.title('Overlay Prediction')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Hitung waktu komputasi\n",
    "        end_time = time.time()\n",
    "        computation_time = end_time - start_time\n",
    "        computation_times.append(computation_time)  # Append computation time\n",
    "        print(f\"Image {i+1}: Computation Time = {computation_time:.4f} seconds\")\n",
    "        \n",
    "        # Hitung metrik untuk setiap kelas\n",
    "        for cls in range(num_classes):\n",
    "            y_true_class = (y_val_class_index[i] == cls).astype(np.uint8)\n",
    "            y_pred_class = (predictions_class_index[i] == cls).astype(np.uint8)\n",
    "\n",
    "            dice = dice_coefficient(y_true_class, y_pred_class)\n",
    "            iou = iou_score(y_true_class, y_pred_class)\n",
    "\n",
    "            mean_dice[cls] += dice\n",
    "            mean_iou[cls] += iou\n",
    "\n",
    "            print(f\"Class {cls} (Color: {colormap[cls]}): Dice = {dice:.4f}, IoU = {iou:.4f}\")\n",
    "            print(\"--------------------------------------------------\")\n",
    "\n",
    "        # Hitung jumlah piksel warna merah dan biru serta persentase korosi\n",
    "        red_pixel_count = np.sum((predicted_rgb == [255, 0, 0]).all(axis=-1))\n",
    "        blue_pixel = np.sum((predicted_rgb == [0, 0, 255]).all(axis=-1))\n",
    "        blue_pixel_count = red_pixel_count + blue_pixel\n",
    "        corrosion_percentage = (red_pixel_count / blue_pixel_count) * 100 if blue_pixel_count > 0 else 0\n",
    "    \n",
    "        # Tampilkan hasil\n",
    "        print(f\"Red Pixel Count (Corrosion): {red_pixel_count}\")\n",
    "        print(f\"Blue Pixel Count (Pipe): {blue_pixel_count}\")\n",
    "        print(f\"Corrosion Percentage on Pipe: {corrosion_percentage:.2f}%\")\n",
    "        print(\"=======================================\")           \n",
    "\n",
    "    # Hitung rata-rata metrik\n",
    "    mean_dice /= num_samples\n",
    "    mean_iou /= num_samples\n",
    "\n",
    "    print(\"Mean Evaluation Metrics (Across All Images):\")\n",
    "    for cls in range(num_classes):\n",
    "        print(f\"Class {cls} (Color: {colormap[cls]}): Mean Dice = {mean_dice[cls]:.4f}, Mean IoU = {mean_iou[cls]:.4f}\")\n",
    "    print(\"==================================================\")\n",
    "    \n",
    "    # Hitung dan tampilkan rata-rata waktu komputasi\n",
    "    avg_computation_time = np.mean(computation_times)\n",
    "    print(f\"Average Computation Time per Image: {avg_computation_time:.4f} seconds\")\n",
    "\n",
    "# Fungsi untuk menghitung Confusion Matrix\n",
    "def calculate_confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"Menghitung confusion matrix untuk setiap kelas.\"\"\"\n",
    "    cm = confusion_matrix(y_true.flatten(), y_pred.flatten())\n",
    "    return cm\n",
    "\n",
    "# Load data val\n",
    "X_val_images, y_val_masks, y_val_one_hot_masks = load_and_one_hot_encode(val_original_dir, val_mask_dir, target_size)\n",
    "\n",
    "# Konversi val data ke format yang sesuai untuk evaluasi\n",
    "y_val_class_index = np.argmax(y_val_one_hot_masks, axis=-1)\n",
    "\n",
    "# Evaluasi model pada data val\n",
    "evaluate_model_on_val_data(model, X_val_images, y_val_one_hot_masks, colormap)\n",
    "\n",
    "# Hitung confusion matrix\n",
    "y_val_pred_class_index = np.argmax(model.predict(X_val_images), axis=-1)\n",
    "cm = calculate_confusion_matrix(y_val_class_index, y_val_pred_class_index)\n",
    "\n",
    "# Visualisasi confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c82fa-788c-4ea2-8464-27c3c94108f7",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01495125-1d97-4f0c-bcd5-d6fee6cdddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "export_dir = 'model/256A_B8E100_BiSeNetV3-EfficientNetB1'\n",
    "tf.saved_model.save(model, export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c7179-362a-42d0-9575-355d1fdca3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb246544-38bc-4c0b-8d6d-3880aaf1ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_file = pathlib.Path('256A_B8E100_BiSeNetV3-EfficientNetB1.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f71780-70b8-4eee-8eb4-9412a7d3ef23",
   "metadata": {},
   "source": [
    "# Load Model & Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30add3-6912-46a8-8544-c91a61937fc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, jaccard_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Model\n",
    "model_path = 'C:\\\\Users\\\\Admin\\\\Documents\\\\Model\\\\BiSeNetV3\\\\model\\\\256A_B8E100_BiSeNetV3-EfficientNetB1.keras'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Visualisasi dengan Metriks Evaluasi\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    \"\"\"Menghitung Dice Coefficient\"\"\"\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection + 1e-7) / (np.sum(y_true) + np.sum(y_pred) + 1e-7)\n",
    "\n",
    "def iou_score(y_true, y_pred):\n",
    "    \"\"\"Menghitung IoU Score\"\"\"\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return (intersection + 1e-7) / (union + 1e-7)\n",
    "\n",
    "def convert_to_rgb(mask, colormap):\n",
    "    \"\"\"Konversi mask kelas ke RGB menggunakan colormap\"\"\"\n",
    "    h, w = mask.shape\n",
    "    rgb_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for cls in range(len(colormap)):\n",
    "        rgb_mask[mask == cls] = colormap[cls]\n",
    "    return rgb_mask\n",
    "\n",
    "def overlay_images(original, mask, opacity=0.5):\n",
    "    \"\"\"Menggabungkan gambar asli dan mask dengan efek transparansi.\"\"\"\n",
    "    overlay = cv2.addWeighted(original, 1 - opacity, mask, opacity, 0)\n",
    "    return overlay\n",
    "\n",
    "def evaluate_model_on_test_data(model, X, y_test, colormap):\n",
    "    \"\"\"\n",
    "    Mengevaluasi model pada data val dan menampilkan hasil prediksi dengan metrik evaluasi, overlay, dan waktu komputasi.\n",
    "    \n",
    "    Args:\n",
    "        model: Model yang telah dilatih.\n",
    "        X: Gambar input val.\n",
    "        y_test: Ground truth mask val.\n",
    "        colormap: Dictionary yang berisi peta warna untuk setiap kelas.\n",
    "    \"\"\"\n",
    "    predictions = model.predict(X)\n",
    "    predictions_class_index = np.argmax(predictions, axis=-1)\n",
    "    y_test_class_index = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    num_classes = y_test.shape[-1]\n",
    "    mean_dice = np.zeros(num_classes)\n",
    "    mean_iou = np.zeros(num_classes)\n",
    "    \n",
    "    num_samples = X.shape[0]  # Total sample in the val set\n",
    "    computation_times = []  # List to store computation times for each prediction\n",
    "    \n",
    "    # Tampilkan beberapa sampel hasil prediksi\n",
    "    for i in range(num_samples):\n",
    "        start_time = time.time()  # Start the timer for prediction\n",
    "        \n",
    "        plt.figure(figsize=(18, 6))\n",
    "        \n",
    "        # Gambar asli\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(X[i])\n",
    "        plt.title('Original Image')\n",
    "\n",
    "        # Ground truth mask\n",
    "        plt.subplot(1, 4, 2)\n",
    "        ground_truth_rgb = convert_to_rgb(y_test_class_index[i], colormap)\n",
    "        plt.imshow(ground_truth_rgb)\n",
    "        plt.title('Ground Truth Mask')\n",
    "\n",
    "        # Prediksi mask\n",
    "        plt.subplot(1, 4, 3)\n",
    "        predicted_rgb = convert_to_rgb(predictions_class_index[i], colormap)\n",
    "        plt.imshow(predicted_rgb)\n",
    "        plt.title('Predicted Mask')\n",
    "        \n",
    "        # Overlay gambar asli dengan prediksi\n",
    "        overlay = overlay_images(X[i], predicted_rgb, opacity=0.4)  # Ubah opacity sesuai keinginan\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(overlay)\n",
    "        plt.title('Overlay Prediction')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Hitung waktu komputasi\n",
    "        end_time = time.time()\n",
    "        computation_time = end_time - start_time\n",
    "        computation_times.append(computation_time)  # Append computation time\n",
    "        print(f\"Image {i+1}: Computation Time = {computation_time:.4f} seconds\")\n",
    "        \n",
    "        # Hitung metrik untuk setiap kelas\n",
    "        for cls in range(num_classes):\n",
    "            y_true_class = (y_test_class_index[i] == cls).astype(np.uint8)\n",
    "            y_pred_class = (predictions_class_index[i] == cls).astype(np.uint8)\n",
    "\n",
    "            dice = dice_coefficient(y_true_class, y_pred_class)\n",
    "            iou = iou_score(y_true_class, y_pred_class)\n",
    "\n",
    "            mean_dice[cls] += dice\n",
    "            mean_iou[cls] += iou\n",
    "\n",
    "            print(f\"Class {cls} (Color: {colormap[cls]}): Dice = {dice:.4f}, IoU = {iou:.4f}\")\n",
    "            print(\"--------------------------------------------------\")\n",
    "\n",
    "        # Hitung jumlah piksel warna merah dan biru serta persentase korosi\n",
    "        red_pixel_count = np.sum((predicted_rgb == [255, 0, 0]).all(axis=-1))\n",
    "        blue_pixel = np.sum((predicted_rgb == [0, 0, 255]).all(axis=-1))\n",
    "        blue_pixel_count = red_pixel_count + blue_pixel\n",
    "        corrosion_percentage = (red_pixel_count / blue_pixel_count) * 100 if blue_pixel_count > 0 else 0\n",
    "    \n",
    "        # Tampilkan hasil\n",
    "        print(f\"Red Pixel Count (Corrosion): {red_pixel_count}\")\n",
    "        print(f\"Blue Pixel Count (Pipe): {blue_pixel_count}\")\n",
    "        print(f\"Corrosion Percentage on Pipe: {corrosion_percentage:.2f}%\")\n",
    "        print(\"=======================================\")          \n",
    "\n",
    "    # Hitung rata-rata metrik\n",
    "    mean_dice /= num_samples\n",
    "    mean_iou /= num_samples\n",
    "\n",
    "    print(\"Mean Evaluation Metrics (Across All Images):\")\n",
    "    for cls in range(num_classes):\n",
    "        print(f\"Class {cls} (Color: {colormap[cls]}): Mean Dice = {mean_dice[cls]:.4f}, Mean IoU = {mean_iou[cls]:.4f}\")\n",
    "    print(\"==================================================\")\n",
    "    \n",
    "    # Hitung dan tampilkan rata-rata waktu komputasi\n",
    "    avg_computation_time = np.mean(computation_times)\n",
    "    print(f\"Average Computation Time per Image: {avg_computation_time:.4f} seconds\")\n",
    "\n",
    "# Fungsi untuk menghitung Confusion Matrix\n",
    "def calculate_confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"Menghitung confusion matrix untuk setiap kelas.\"\"\"\n",
    "    cm = confusion_matrix(y_true.flatten(), y_pred.flatten())\n",
    "    return cm\n",
    "\n",
    "# Load data val\n",
    "X_test_images, y_test_masks, y_test_one_hot_masks = load_and_one_hot_encode(test_original_dir, test_mask_dir, target_size)\n",
    "\n",
    "# Konversi test data ke format yang sesuai untuk evaluasi\n",
    "y_test_class_index = np.argmax(y_test_one_hot_masks, axis=-1)\n",
    "\n",
    "# Evaluasi model pada data val\n",
    "evaluate_model_on_test_data(model, X_test_images, y_test_one_hot_masks, colormap)\n",
    "\n",
    "# Hitung confusion matrix\n",
    "y_test_pred_class_index = np.argmax(model.predict(X_test_images), axis=-1)\n",
    "cm = calculate_confusion_matrix(y_test_class_index, y_test_pred_class_index)\n",
    "\n",
    "# Visualisasi confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57374dd8-e278-4300-84b6-387293c87a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate IoU and Dice Coefficient\n",
    "def calculate_metrics(y_true, y_pred, num_classes=3):\n",
    "    \"\"\"Calculate IoU and Dice Coefficient for each class.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        intersection = np.logical_and(y_true == class_idx, y_pred == class_idx).sum()\n",
    "        union = np.logical_or(y_true == class_idx, y_pred == class_idx).sum()\n",
    "        dice_numerator = 2 * intersection\n",
    "        dice_denominator = (y_true == class_idx).sum() + (y_pred == class_idx).sum()\n",
    "        \n",
    "        iou = intersection / union if union != 0 else 0.0\n",
    "        dice = dice_numerator / dice_denominator if dice_denominator != 0 else 0.0\n",
    "        \n",
    "        results.append({\n",
    "            \"Class\": class_idx,\n",
    "            \"Intersection\": intersection,\n",
    "            \"Union\": union,\n",
    "            \"IoU\": iou,\n",
    "            \"Dice Numerator\": dice_numerator,\n",
    "            \"Dice Denominator\": dice_denominator,\n",
    "            \"Dice Coefficient\": dice\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Evaluate model on test images\n",
    "y_test_pred_class_index = np.argmax(model.predict(X_test_images), axis=-1)\n",
    "\n",
    "# Calculate metrics for each image\n",
    "all_metrics = []\n",
    "for i in range(len(X_test_images)):\n",
    "    metrics_df = calculate_metrics(y_test_class_index[i], y_test_pred_class_index[i])\n",
    "    metrics_df.insert(0, \"Image Index\", i+1)  # Add image index\n",
    "    all_metrics.append(metrics_df)\n",
    "    \n",
    "    # Display each image's metrics in table format\n",
    "    print(f\"Metrics for Image {i+1}\")\n",
    "    print(metrics_df)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "total_metrics_df = pd.concat(all_metrics, ignore_index=True)\n",
    "\n",
    "# Visualizing metrics\n",
    "g = sns.catplot(data=total_metrics_df, x=\"Class\", y=\"IoU\", hue=\"Image Index\", kind=\"bar\", height=5, aspect=2)\n",
    "g.set_axis_labels(\"Class\", \"IoU Score\")\n",
    "plt.title(\"IoU Scores for Each Class and Image\")\n",
    "plt.show()\n",
    "\n",
    "g = sns.catplot(data=total_metrics_df, x=\"Class\", y=\"Dice Coefficient\", hue=\"Image Index\", kind=\"bar\", height=5, aspect=2)\n",
    "g.set_axis_labels(\"Class\", \"Dice Coefficient Score\")\n",
    "plt.title(\"Dice Coefficient Scores for Each Class and Image\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
